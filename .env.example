-------- runtime options ----------
LLM_TAG=v2.0.0 # change to v2.1.0 on upgrade
MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct
GPU_MEMORY_UTILIZATION=0.85
HF_HOME=/models/.cache
# QUANTIZATION=awq # optional: set to 'awq', 'gptq', or leave empty/None for standard loading

LLM_API_KEY=
