MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct
GPU_MEMORY_UTILIZATION=0.85
HF_HOME=/models/.cache
# LLM_API_KEY=
