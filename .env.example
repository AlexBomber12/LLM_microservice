-------- runtime options ----------
LLM_TAG=v1.5.0 # change to v1.6.0 on upgrade
MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct
GPU_MEMORY_UTILIZATION=0.85
HF_HOME=/models/.cache
# QUANTIZATION=awq  # optional, one of: awq, gptq, ...; leave empty for standard weights

LLM_API_KEY=
